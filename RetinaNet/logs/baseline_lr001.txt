/home/hslee/anaconda3/lib/python3.11/site-packages/torch/distributed/launch.py:181: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use-env is set by default in torchrun.
If your script expects `--local-rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
| distributed init (rank 0): env://
| distributed init (rank 1): env://
Namespace(data_path='/media/data/coco/', dataset='coco', model='my_retinanet_resnet50_fpn', device='cuda', batch_size=8, epochs=26, workers=8, opt='sgd', lr=0.01, momentum=0.9, weight_decay=0.0001, norm_weight_decay=None, lr_scheduler='multisteplr', lr_step_size=8, lr_steps=[16, 22], lr_gamma=0.1, print_freq=20, output_dir='.', resume='', start_epoch=0, aspect_ratio_group_factor=3, rpn_score_thresh=None, trainable_backbone_layers=None, data_augmentation='hflip', sync_bn=False, test_only=False, use_deterministic_algorithms=False, world_size=2, dist_url='env://', weights=None, weights_backbone='ResNet50_Weights.IMAGENET1K_V1', amp=False, use_copypaste=False, backend='pil', use_v2=False, rank=0, gpu=0, distributed=True, dist_backend='nccl')
Loading data
root:  /media/data/coco/
img_folder:  train2017
loading annotations into memory...
Done (t=11.62s)
creating index...
index created!
root:  /media/data/coco/
img_folder:  val2017
loading annotations into memory...
Done (t=0.34s)
creating index...
index created!
Creating data loaders
Using [0, 0.5, 0.6299605249474365, 0.7937005259840997, 1.0, 1.259921049894873, 1.5874010519681991, 2.0, inf] as bins for aspect ratio quantization
Count of instances per bin: [  104   982 24236  2332  8225 74466  5763  1158]
Creating model
/home/hslee/Desktop/Backbone-Neck_Self-Distillation/RetinaNet/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/home/hslee/Desktop/Backbone-Neck_Self-Distillation/RetinaNet/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
return_layers: {'layer2': '0', 'layer3': '1', 'layer4': '2'}
extra_blocks: LastLevelP6P7(
  (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
  (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
)
backbone: BackboneWithFPN(
  (body): IntermediateLayerGetter(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): FrozenBatchNorm2d(64, eps=1e-05)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(64, eps=1e-05)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(64, eps=1e-05)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(256, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): FrozenBatchNorm2d(256, eps=1e-05)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(64, eps=1e-05)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(64, eps=1e-05)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(256, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(64, eps=1e-05)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(64, eps=1e-05)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(256, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(128, eps=1e-05)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(512, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d(512, eps=1e-05)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(128, eps=1e-05)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(512, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(128, eps=1e-05)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(512, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(128, eps=1e-05)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(128, eps=1e-05)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(512, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d(1024, eps=1e-05)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(256, eps=1e-05)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(256, eps=1e-05)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(1024, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(512, eps=1e-05)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(512, eps=1e-05)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): FrozenBatchNorm2d(2048, eps=1e-05)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(512, eps=1e-05)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(512, eps=1e-05)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): FrozenBatchNorm2d(512, eps=1e-05)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): FrozenBatchNorm2d(512, eps=1e-05)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): FrozenBatchNorm2d(2048, eps=1e-05)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (fpn): FeaturePyramidNetwork(
    (inner_blocks): ModuleList(
      (0): Conv2dNormActivation(
        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): Conv2dNormActivation(
        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): Conv2dNormActivation(
        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (layer_blocks): ModuleList(
      (0-2): 3 x Conv2dNormActivation(
        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
    (extra_blocks): LastLevelP6P7(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
  )
)
Start training
Epoch: [0]  [   0/7329]  eta: 5:07:33  lr: 0.000020  loss: 2.1889 (2.1889)  bbox_regression: 0.8309 (0.8309)  classification: 1.3579 (1.3579)  time: 2.5179  data: 1.1515  max mem: 10509
Epoch: [0]  [  20/7329]  eta: 1:09:11  lr: 0.000220  loss: 1.9808 (2.0116)  bbox_regression: 0.6948 (0.7186)  classification: 1.2828 (1.2930)  time: 0.4705  data: 0.0138  max mem: 11861
Epoch: [0]  [  40/7329]  eta: 1:03:35  lr: 0.000420  loss: 2.0018 (2.0133)  bbox_regression: 0.6840 (0.7159)  classification: 1.2935 (1.2975)  time: 0.4767  data: 0.0177  max mem: 11864
Epoch: [0]  [  60/7329]  eta: 1:01:47  lr: 0.000619  loss: 1.9722 (2.0024)  bbox_regression: 0.6885 (0.7101)  classification: 1.2803 (1.2923)  time: 0.4827  data: 0.0188  max mem: 11882
Epoch: [0]  [  80/7329]  eta: 1:00:36  lr: 0.000819  loss: 2.0063 (2.0043)  bbox_regression: 0.6991 (0.7113)  classification: 1.2867 (1.2930)  time: 0.4763  data: 0.0163  max mem: 11882
Epoch: [0]  [ 100/7329]  eta: 0:59:53  lr: 0.001019  loss: 1.9742 (2.0003)  bbox_regression: 0.6932 (0.7100)  classification: 1.2797 (1.2903)  time: 0.4783  data: 0.0167  max mem: 11882
Epoch: [0]  [ 120/7329]  eta: 0:59:18  lr: 0.001219  loss: 1.9788 (1.9978)  bbox_regression: 0.6982 (0.7090)  classification: 1.2658 (1.2888)  time: 0.4764  data: 0.0140  max mem: 11882
Epoch: [0]  [ 140/7329]  eta: 0:58:49  lr: 0.001419  loss: 1.9660 (1.9958)  bbox_regression: 0.6854 (0.7075)  classification: 1.2794 (1.2883)  time: 0.4742  data: 0.0171  max mem: 11882
Epoch: [0]  [ 160/7329]  eta: 0:58:29  lr: 0.001618  loss: 1.9790 (1.9950)  bbox_regression: 0.6844 (0.7067)  classification: 1.2854 (1.2883)  time: 0.4803  data: 0.0190  max mem: 11882
Epoch: [0]  [ 180/7329]  eta: 0:58:07  lr: 0.001818  loss: 1.9764 (1.9929)  bbox_regression: 0.6734 (0.7043)  classification: 1.2797 (1.2886)  time: 0.4734  data: 0.0163  max mem: 11882
Epoch: [0]  [ 200/7329]  eta: 0:57:49  lr: 0.002018  loss: 1.9532 (1.9932)  bbox_regression: 0.6789 (0.7043)  classification: 1.2773 (1.2888)  time: 0.4770  data: 0.0191  max mem: 11882
Epoch: [0]  [ 220/7329]  eta: 0:57:35  lr: 0.002218  loss: 1.9748 (1.9922)  bbox_regression: 0.6868 (0.7037)  classification: 1.2693 (1.2886)  time: 0.4788  data: 0.0167  max mem: 11883
Epoch: [0]  [ 240/7329]  eta: 0:57:19  lr: 0.002418  loss: 1.9673 (1.9897)  bbox_regression: 0.6716 (0.7017)  classification: 1.2689 (1.2879)  time: 0.4769  data: 0.0167  max mem: 11883
Epoch: [0]  [ 260/7329]  eta: 0:57:06  lr: 0.002617  loss: 1.9526 (1.9873)  bbox_regression: 0.6746 (0.7001)  classification: 1.2679 (1.2872)  time: 0.4778  data: 0.0183  max mem: 11890
Epoch: [0]  [ 280/7329]  eta: 0:56:50  lr: 0.002817  loss: 1.9626 (1.9864)  bbox_regression: 0.6906 (0.6997)  classification: 1.2622 (1.2867)  time: 0.4735  data: 0.0164  max mem: 11890
Epoch: [0]  [ 300/7329]  eta: 0:56:40  lr: 0.003017  loss: 1.9478 (1.9853)  bbox_regression: 0.6771 (0.6988)  classification: 1.2630 (1.2865)  time: 0.4814  data: 0.0160  max mem: 11890
Epoch: [0]  [ 320/7329]  eta: 0:56:26  lr: 0.003217  loss: 1.9443 (1.9845)  bbox_regression: 0.6745 (0.6987)  classification: 1.2646 (1.2857)  time: 0.4750  data: 0.0166  max mem: 11890
Epoch: [0]  [ 340/7329]  eta: 0:56:13  lr: 0.003417  loss: 1.9560 (1.9835)  bbox_regression: 0.6850 (0.6988)  classification: 1.2610 (1.2847)  time: 0.4740  data: 0.0162  max mem: 11925
Epoch: [0]  [ 360/7329]  eta: 0:56:00  lr: 0.003616  loss: 1.8840 (1.9789)  bbox_regression: 0.6765 (0.6980)  classification: 1.2085 (1.2808)  time: 0.4745  data: 0.0177  max mem: 11925
Epoch: [0]  [ 380/7329]  eta: 0:55:48  lr: 0.003816  loss: 1.8482 (1.9727)  bbox_regression: 0.6601 (0.6969)  classification: 1.1644 (1.2758)  time: 0.4760  data: 0.0195  max mem: 11925
Epoch: [0]  [ 400/7329]  eta: 0:55:37  lr: 0.004016  loss: 1.8493 (1.9663)  bbox_regression: 0.6735 (0.6965)  classification: 1.1373 (1.2698)  time: 0.4778  data: 0.0202  max mem: 11925
Epoch: [0]  [ 420/7329]  eta: 0:55:26  lr: 0.004216  loss: 1.7763 (1.9572)  bbox_regression: 0.6455 (0.6944)  classification: 1.1205 (1.2628)  time: 0.4771  data: 0.0181  max mem: 11925
Epoch: [0]  [ 440/7329]  eta: 0:55:15  lr: 0.004416  loss: 1.7251 (1.9474)  bbox_regression: 0.6304 (0.6923)  classification: 1.1000 (1.2552)  time: 0.4775  data: 0.0192  max mem: 11925
Epoch: [0]  [ 460/7329]  eta: 0:55:04  lr: 0.004615  loss: 1.7240 (1.9393)  bbox_regression: 0.6403 (0.6905)  classification: 1.0995 (1.2488)  time: 0.4765  data: 0.0179  max mem: 11925
Epoch: [0]  [ 480/7329]  eta: 0:54:53  lr: 0.004815  loss: 1.6788 (1.9289)  bbox_regression: 0.6396 (0.6886)  classification: 1.0295 (1.2402)  time: 0.4765  data: 0.0183  max mem: 11925
Epoch: [0]  [ 500/7329]  eta: 0:54:42  lr: 0.005015  loss: 1.6854 (1.9198)  bbox_regression: 0.6358 (0.6868)  classification: 1.0401 (1.2329)  time: 0.4779  data: 0.0170  max mem: 11925
Epoch: [0]  [ 520/7329]  eta: 0:54:31  lr: 0.005215  loss: 1.6325 (1.9101)  bbox_regression: 0.5909 (0.6843)  classification: 1.0060 (1.2257)  time: 0.4718  data: 0.0184  max mem: 11925
Epoch: [0]  [ 540/7329]  eta: 0:54:20  lr: 0.005415  loss: 1.6051 (1.8992)  bbox_regression: 0.6060 (0.6816)  classification: 0.9883 (1.2175)  time: 0.4765  data: 0.0150  max mem: 11925
Epoch: [0]  [ 560/7329]  eta: 0:54:10  lr: 0.005614  loss: 1.5980 (1.8894)  bbox_regression: 0.5902 (0.6787)  classification: 1.0035 (1.2107)  time: 0.4790  data: 0.0202  max mem: 11925
Epoch: [0]  [ 580/7329]  eta: 0:53:59  lr: 0.005814  loss: 1.5743 (1.8797)  bbox_regression: 0.5921 (0.6760)  classification: 0.9851 (1.2037)  time: 0.4756  data: 0.0153  max mem: 11925
Epoch: [0]  [ 600/7329]  eta: 0:53:50  lr: 0.006014  loss: 1.5331 (1.8687)  bbox_regression: 0.5845 (0.6729)  classification: 0.9686 (1.1958)  time: 0.4788  data: 0.0161  max mem: 11925
Epoch: [0]  [ 620/7329]  eta: 0:53:39  lr: 0.006214  loss: 1.6087 (1.8603)  bbox_regression: 0.5882 (0.6705)  classification: 1.0162 (1.1898)  time: 0.4778  data: 0.0183  max mem: 11925
Epoch: [0]  [ 640/7329]  eta: 0:53:29  lr: 0.006414  loss: 1.5507 (1.8510)  bbox_regression: 0.5715 (0.6679)  classification: 0.9639 (1.1830)  time: 0.4758  data: 0.0175  max mem: 11925
Epoch: [0]  [ 660/7329]  eta: 0:53:19  lr: 0.006613  loss: 1.5059 (1.8407)  bbox_regression: 0.5562 (0.6645)  classification: 0.9516 (1.1763)  time: 0.4775  data: 0.0177  max mem: 11925
Epoch: [0]  [ 680/7329]  eta: 0:53:08  lr: 0.006813  loss: 1.4893 (1.8312)  bbox_regression: 0.5422 (0.6612)  classification: 0.9285 (1.1700)  time: 0.4732  data: 0.0170  max mem: 11925
Epoch: [0]  [ 700/7329]  eta: 0:52:58  lr: 0.007013  loss: 1.4872 (1.8216)  bbox_regression: 0.5324 (0.6580)  classification: 0.9434 (1.1636)  time: 0.4767  data: 0.0168  max mem: 11925
Epoch: [0]  [ 720/7329]  eta: 0:52:47  lr: 0.007213  loss: 1.4840 (1.8130)  bbox_regression: 0.5562 (0.6552)  classification: 0.9397 (1.1579)  time: 0.4711  data: 0.0163  max mem: 11925
Epoch: [0]  [ 740/7329]  eta: 0:52:35  lr: 0.007413  loss: 1.4359 (1.8031)  bbox_regression: 0.5449 (0.6525)  classification: 0.8840 (1.1506)  time: 0.4695  data: 0.0160  max mem: 11925
Epoch: [0]  [ 760/7329]  eta: 0:52:25  lr: 0.007612  loss: 1.4316 (1.7941)  bbox_regression: 0.5311 (0.6499)  classification: 0.8790 (1.1442)  time: 0.4765  data: 0.0182  max mem: 11925
Epoch: [0]  [ 780/7329]  eta: 0:52:15  lr: 0.007812  loss: 1.4340 (1.7853)  bbox_regression: 0.5579 (0.6475)  classification: 0.8848 (1.1378)  time: 0.4753  data: 0.0186  max mem: 11925
Epoch: [0]  [ 800/7329]  eta: 0:52:05  lr: 0.008012  loss: 1.3865 (1.7752)  bbox_regression: 0.5324 (0.6449)  classification: 0.8359 (1.1303)  time: 0.4762  data: 0.0196  max mem: 11925
Epoch: [0]  [ 820/7329]  eta: 0:51:55  lr: 0.008212  loss: 1.3765 (1.7657)  bbox_regression: 0.5582 (0.6426)  classification: 0.8225 (1.1231)  time: 0.4730  data: 0.0166  max mem: 11925
Epoch: [0]  [ 840/7329]  eta: 0:51:44  lr: 0.008412  loss: 1.8444 (1.7676)  bbox_regression: 0.5886 (0.6412)  classification: 1.2451 (1.1263)  time: 0.4694  data: 0.0167  max mem: 11925
Epoch: [0]  [ 860/7329]  eta: 0:51:34  lr: 0.008611  loss: 1.7678 (1.7677)  bbox_regression: 0.5685 (0.6397)  classification: 1.1931 (1.1280)  time: 0.4747  data: 0.0179  max mem: 11925
Epoch: [0]  [ 880/7329]  eta: 0:51:24  lr: 0.008811  loss: 1.6489 (1.7650)  bbox_regression: 0.5652 (0.6382)  classification: 1.0824 (1.1268)  time: 0.4782  data: 0.0173  max mem: 11925
Epoch: [0]  [ 900/7329]  eta: 0:51:14  lr: 0.009011  loss: 1.5822 (1.7610)  bbox_regression: 0.5553 (0.6366)  classification: 1.0348 (1.1244)  time: 0.4771  data: 0.0193  max mem: 11925
Epoch: [0]  [ 920/7329]  eta: 0:51:05  lr: 0.009211  loss: 1.5820 (1.7577)  bbox_regression: 0.5325 (0.6346)  classification: 1.0544 (1.1231)  time: 0.4784  data: 0.0168  max mem: 11925
Epoch: [0]  [ 940/7329]  eta: 0:50:55  lr: 0.009411  loss: 1.3986 (1.7506)  bbox_regression: 0.5059 (0.6322)  classification: 0.8931 (1.1184)  time: 0.4788  data: 0.0197  max mem: 11925
Epoch: [0]  [ 960/7329]  eta: 0:50:45  lr: 0.009610  loss: 1.3780 (1.7430)  bbox_regression: 0.5226 (0.6300)  classification: 0.8624 (1.1130)  time: 0.4742  data: 0.0181  max mem: 11925
Epoch: [0]  [ 980/7329]  eta: 0:50:35  lr: 0.009810  loss: 1.3864 (1.7358)  bbox_regression: 0.5052 (0.6275)  classification: 0.8618 (1.1083)  time: 0.4711  data: 0.0152  max mem: 11925
Epoch: [0]  [1000/7329]  eta: 0:50:25  lr: 0.010000  loss: 1.6329 (1.7339)  bbox_regression: 0.5340 (0.6257)  classification: 1.1081 (1.1082)  time: 0.4752  data: 0.0163  max mem: 11925
Epoch: [0]  [1020/7329]  eta: 0:50:15  lr: 0.010000  loss: 1.5623 (1.7308)  bbox_regression: 0.5237 (0.6239)  classification: 1.0290 (1.1069)  time: 0.4762  data: 0.0186  max mem: 11925
Epoch: [0]  [1040/7329]  eta: 0:50:04  lr: 0.010000  loss: 1.6892 (1.7302)  bbox_regression: 0.5319 (0.6224)  classification: 1.1506 (1.1078)  time: 0.4698  data: 0.0165  max mem: 11925
