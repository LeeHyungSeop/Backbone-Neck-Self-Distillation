{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def loss(S, T, gamma = 1):\n",
    "    N = S.shape[0]  # Batch size\n",
    "    loss = (gamma / N) * torch.sum((S - T) ** 2)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def total_loss(S_s, T_s, S_m, T_m, S_l, T_l, gamma):\n",
    "    L_s = loss(S_s, T_s, gamma)\n",
    "    L_m = loss(S_m, T_m)\n",
    "    L_l = loss(S_l, T_l)\n",
    "    return L_s + L_m + L_l\n",
    "\n",
    "\n",
    "# 가상의 모델 출력 (예제)\n",
    "batch_size, H, W, C = 4, 32, 32, 64\n",
    "\n",
    "S_s = torch.randn(batch_size, H, W, C)\n",
    "T_s = torch.randn(batch_size, H, W, C)\n",
    "S_m = torch.randn(batch_size, H, W, C)\n",
    "T_m = torch.randn(batch_size, H, W, C)\n",
    "S_l = torch.randn(batch_size, H, W, C)\n",
    "T_l = torch.randn(batch_size, H, W, C)\n",
    "\n",
    "gamma = 0.05\n",
    "\n",
    "# 손실 계산\n",
    "loss = total_loss(S_s, T_s, S_m, T_m, S_l, T_l, gamma)\n",
    "print(f'Total Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL divergence between two distributions test\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.functional as F\n",
    "\n",
    "# feature map (bs, h, w, c)\n",
    "input = np.random.rand(4, 512, 20, 20)\n",
    "target = np.random.rand(4, 512, 20, 20)\n",
    "\n",
    "input = torch.softmax(torch.tensor(input), dim=-1)\n",
    "\n",
    "# KL divergence\n",
    "kl_div = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "loss = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5468700528144836\n",
      "0.5468700528144836\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "def js_divergence(p, q):\n",
    "    \"\"\"\n",
    "    Compute the Jensen-Shannon Divergence between two probability distributions.\n",
    "    \"\"\"\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * (F.kl_div(p.log(), m, reduction='batchmean') + F.kl_div(q.log(), m, reduction='batchmean'))\n",
    "\n",
    "def compute_js_distance(tensor1, tensor2):\n",
    "    \"\"\"\n",
    "    Compute the Jensen-Shannon distance between two tensors.\n",
    "    \"\"\"\n",
    "    # Reshape tensors to 2D\n",
    "    tensor1 = tensor1.view(tensor1.size(0), -1)\n",
    "    tensor2 = tensor2.view(tensor2.size(0), -1)\n",
    "\n",
    "    # Convert tensors to probability distributions\n",
    "    p = F.softmax(tensor1, dim=1)\n",
    "    q = F.softmax(tensor2, dim=1)\n",
    "\n",
    "    # Compute the JS divergence\n",
    "    js_div = js_divergence(p, q)\n",
    "\n",
    "    # Convert divergence to distance\n",
    "    js_distance = torch.sqrt(js_div)\n",
    "    return js_distance\n",
    "\n",
    "# Example tensors\n",
    "tensor1 = torch.randn(4, 256, 84, 84)\n",
    "tensor2 = torch.randn(4, 256, 84, 84)\n",
    "\n",
    "\n",
    "# Compute the JS distance\n",
    "js_distance = compute_js_distance(tensor1, tensor2)\n",
    "print(js_distance.item())\n",
    "js_distance = compute_js_distance(tensor2, tensor1)\n",
    "print(js_distance.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------\n",
      "torch.Size([4, 256, 20, 20]) torch.Size([4, 256, 20, 20])\n",
      "torch.Size([4, 20, 20]) torch.Size([4, 20, 20])\n",
      "tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]]) tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],\n",
      "\n",
      "        [[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         ...,\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]])\n",
      "---------------\n",
      "torch.Size([4, 256, 400]) torch.Size([4, 256, 400])\n",
      "torch.Size([4, 400]) torch.Size([4, 400])\n",
      "tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]]) tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ta= torch.randn(4, 256, 20, 20)\n",
    "tb = torch.randn(4, 256, 20, 20)\n",
    "\n",
    "print(\"---------------\")\n",
    "\n",
    "t1 = torch.softmax(ta, dim=1)\n",
    "t2 = torch.softmax(tb, dim=1)\n",
    "\n",
    "print(t1.shape, t2.shape)\n",
    "print(t1.sum(dim=1).shape, t2.sum(dim=1).shape)\n",
    "print(t1.sum(dim=1), t2.sum(dim=1)) \n",
    "\n",
    "print(\"---------------\")\n",
    "\n",
    "t3 = ta.view(ta.size(0), ta.size(1), -1)\n",
    "t4 = tb.view(tb.size(0), tb.size(1), -1)\n",
    "t3 = torch.softmax(t3, dim=1)\n",
    "t4 = torch.softmax(t4, dim=1)\n",
    "\n",
    "print(t3.shape, t4.shape)\n",
    "print(t3.sum(dim=1).shape, t4.sum(dim=1).shape)\n",
    "print(t3.sum(dim=1), t4.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
